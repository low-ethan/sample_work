{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ajb25\\pycharmprojects\\capstone-case-studies\\venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ajb25\\pycharmprojects\\capstone-case-studies\\venv\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ajb25\\pycharmprojects\\capstone-case-studies\\venv\\lib\\site-packages (from xgboost) (1.23.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ajb25\\PycharmProjects\\capstone-case-studies\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "sentences = pd.read_csv('Sentence_Annotation_Assignments_Final_Dataset.tsv', sep='\t')\n",
    "sentences.drop(['id', 'text', 'source'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Trying to predict satisfaction based on everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = ['satisfaction_bucket', 'considerateness_bucket', 'dedication_bucket', 'emotion_bucket']\n",
    "accuracies = {}\n",
    "\n",
    "for i in targets:\n",
    "    y_ = sentences[i]\n",
    "    X_ = sentences.drop([i], axis=1)\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_)\n",
    "    knn_ = KNeighborsClassifier()\n",
    "    knn_.fit(X_train_, y_train_)\n",
    "    \n",
    "    knn_preds_ = knn_.predict(X_test_)\n",
    "    accuracies[i] = accuracy_score(knn_preds_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'satisfaction_bucket': 0.9399477806788512,\n 'considerateness_bucket': 0.9046997389033943,\n 'dedication_bucket': 0.9138381201044387,\n 'emotion_bucket': 0.9255874673629243}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb_targets = ['satisfaction_bucket', 'considerateness_bucket', 'dedication_bucket', 'emotion_bucket']\n",
    "xgb_accuracies = {}\n",
    "\n",
    "for i in xgb_targets:\n",
    "    xgb_y_ = sentences[i] - 1\n",
    "    xgb_X_ = sentences.drop([i], axis=1)\n",
    "    xgb_X_train_, xgb_X_test_, xgb_y_train_, xgb_y_test_ = train_test_split(xgb_X_, xgb_y_)\n",
    "    xgb_ = xgb.XGBClassifier()\n",
    "    xgb_.fit(xgb_X_train_, xgb_y_train_)\n",
    "    \n",
    "    xgb_preds_ = xgb_.predict(xgb_X_test_)\n",
    "    xgb_accuracies[i] = accuracy_score(xgb_preds_, xgb_y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'satisfaction_bucket': 1.0,\n 'considerateness_bucket': 1.0,\n 'dedication_bucket': 1.0,\n 'emotion_bucket': 1.0}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['satisfaction', 'satisfaction_std', 'satisfaction_bucket',\n",
      "       'satisfaction_support', 'considerateness', 'considerateness_std',\n",
      "       'considerateness_bucket', 'considerateness_support', 'dedication',\n",
      "       'dedication_std', 'dedication_bucket', 'dedication_support', 'emotion',\n",
      "       'emotion_std', 'emotion_bucket', 'emotion_support'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sentences.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DATA LEAKAGE\n",
    "Unfortunately, there is a big problem with the label predictor above. There is way too much info being given to the learners (see columns printed above). The learners (KNN and XGB) were just learning David's bucket technique. The raw average of the labels is under the column {signal} and it was being used to predict {signal_bucket}."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SKELETON PREDICTOR\n",
    "Below is XGBoost using ONLY the other bucket labels (3 columns to predict 1 - \"skeleton\").\n",
    "Still does pretty decent with considerateness and dedication getting around 73%. This is still good news. If somehow the final transformer/classifier model is very poor at predicting say, considerateness, but it is good at predicting the other three, then we'd have a decent model for considerateness.\n",
    "There is a slight good news bad news happening here. The good news, is that we picked and defined useful signals that can predict the others. The bad news is that the other group's signals are not very good at predicting ours. I don't find this insanely surprising."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "skel_targets = ['satisfaction_bucket', 'considerateness_bucket', 'dedication_bucket', 'emotion_bucket']\n",
    "skel_accuracies = {}\n",
    "\n",
    "for i in xgb_targets:\n",
    "    skel_y_ = sentences[i] - 1\n",
    "    skel_X_ = sentences[[x for x in xgb_targets if x != i]]\n",
    "    skel_X_train_, skel_X_test_, skel_y_train_, skel_y_test_ = train_test_split(skel_X_, skel_y_)\n",
    "    xgb_skel_ = xgb.XGBClassifier()\n",
    "    xgb_skel_.fit(skel_X_train_, skel_y_train_)\n",
    "\n",
    "    skel_preds_ = xgb_skel_.predict(skel_X_test_)\n",
    "    skel_accuracies[i] = accuracy_score(skel_preds_, skel_y_test_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_bucket': 0.6788511749347258, 'considerateness_bucket': 0.7545691906005222, 'dedication_bucket': 0.7532637075718016, 'emotion_bucket': 0.577023498694517}\n"
     ]
    }
   ],
   "source": [
    "print(skel_accuracies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BABY SKELETON PREDICTOR\n",
    "Now to try a predictive model using only 2 out of the 3 labels to predict 1.\n",
    "Does surprisingly well!\n",
    "So, if we only get two decently accurate models, then we can use those two labels to get some idea for the other two."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "targets = ['satisfaction_bucket', 'considerateness_bucket', 'dedication_bucket', 'emotion_bucket']\n",
    "baby_accuracies = {}\n",
    "\n",
    "for i in targets:\n",
    "    baby_y_ = sentences[i] - 1\n",
    "    rem_buckets = [x for x in targets if x != i]\n",
    "    baby_accuracies[i] = []\n",
    "    for j in range(3):\n",
    "        baby_X_ = sentences[[rem_buckets[j], rem_buckets[(j+1)%3]]]\n",
    "        baby_X_train_, baby_X_test_, baby_y_train_, baby_y_test_ = train_test_split(baby_X_, baby_y_)\n",
    "        xgb_baby_ = xgb.XGBClassifier()\n",
    "        xgb_baby_.fit(baby_X_train_, baby_y_train_)\n",
    "\n",
    "        baby_preds_ = xgb_baby_.predict(baby_X_test_)\n",
    "        baby_accuracies[i].append(accuracy_score(baby_preds_, baby_y_test_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_bucket': [0.6618798955613577, 0.7114882506527415, 0.6631853785900783], 'considerateness_bucket': [0.7650130548302873, 0.7911227154046997, 0.7088772845953003], 'dedication_bucket': [0.7428198433420365, 0.720626631853786, 0.7193211488250653], 'emotion_bucket': [0.587467362924282, 0.49738903394255873, 0.5848563968668408]}\n"
     ]
    }
   ],
   "source": [
    "print(baby_accuracies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BONE PREDICTOR\n",
    "Using only 1 label to predict 1 label!\n",
    "Again, does much better than expected!\n",
    "Baseline accuracy is 20% (Random guess = 1/5)\n",
    "With only 1 other (perfectly accurate) label we can get:\n",
    "> Satisfaction: ~65%\n",
    "> Considerateness: ~71%\n",
    "> Dedication: ~71%\n",
    ">  Emotion: ~50%\n",
    "\n",
    "Emotion is the hardest to predict using the other signals."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "targets = ['satisfaction_bucket', 'considerateness_bucket', 'dedication_bucket', 'emotion_bucket']\n",
    "bone_accuracies = {}\n",
    "\n",
    "for i in targets:\n",
    "    bone_y_ = sentences[i] - 1\n",
    "    rem_buckets = [x for x in targets if x != i]\n",
    "    bone_accuracies[i] = []\n",
    "    for j in range(3):\n",
    "        bone_X_ = sentences[[rem_buckets[j]]]\n",
    "        bone_X_train_, bone_X_test_, bone_y_train_, bone_y_test_ = train_test_split(bone_X_, bone_y_)\n",
    "        xgb_bone_ = xgb.XGBClassifier()\n",
    "        xgb_bone_.fit(bone_X_train_, bone_y_train_)\n",
    "\n",
    "        bone_preds_ = xgb_bone_.predict(bone_X_test_)\n",
    "        bone_accuracies[i].append(accuracy_score(bone_preds_, bone_y_test_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_bucket': [0.6449086161879896, 0.6723237597911227, 0.6488250652741514], 'considerateness_bucket': [0.7232375979112271, 0.7245430809399478, 0.706266318537859], 'dedication_bucket': [0.7127937336814621, 0.7114882506527415, 0.7049608355091384], 'emotion_bucket': [0.5391644908616188, 0.5026109660574413, 0.48433420365535246]}\n"
     ]
    }
   ],
   "source": [
    "print(bone_accuracies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}